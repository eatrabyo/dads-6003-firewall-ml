{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV,ParameterGrid,cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv('data_source/train.csv')\n",
    "# test = pd.read_csv('data_source/test.csv')\n",
    "\n",
    "# train_robust = train.copy()\n",
    "# test_robust = test.copy()\n",
    "\n",
    "x_train = pd.read_csv('data_source/X_train.csv')\n",
    "y_train = pd.read_csv('data_source/y_train.csv')\n",
    "\n",
    "x_test = pd.read_csv('data_source/X_test.csv')\n",
    "y_test = pd.read_csv('data_source/y_test.csv')\n",
    "\n",
    "x_train_std = x_train.copy()\n",
    "y_train_std = y_train.copy()\n",
    "\n",
    "x_train_robust = x_train.copy()\n",
    "y_train_robust = y_train.copy()\n",
    "\n",
    "x_test_std = x_test.copy()\n",
    "y_test_std = y_test.copy()\n",
    "\n",
    "x_test_robust = x_test.copy()\n",
    "y_test_robust = y_test.copy()\n",
    "\n",
    "x_train_std = x_train_std.loc[:,['Destination Port', 'NAT Source Port','Packets', 'Elapsed Time (sec)','Bytes Received']]\n",
    "y_train_std = y_train_std.loc[:,'Action']\n",
    "x_test_std = x_test_std.loc[:,['Destination Port', 'NAT Source Port','Packets', 'Elapsed Time (sec)','Bytes Received']]\n",
    "y_test_std = y_test_std.loc[:,'Action']\n",
    "\n",
    "x_train_robust = x_train_robust.loc[:,['Destination Port', 'NAT Source Port','Packets', 'Elapsed Time (sec)','Bytes Received']]\n",
    "y_train_robust = y_train_robust.loc[:,'Action']\n",
    "x_test_robust = x_test_robust.loc[:,['Destination Port', 'NAT Source Port','Packets', 'Elapsed Time (sec)','Bytes Received']]\n",
    "y_test_robust = y_test_robust.loc[:,'Action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "robust = RobustScaler()\n",
    "\n",
    "x_train_std.loc[:,['Packets','Elapsed Time (sec)','Bytes Received']] = scaler.fit_transform(x_train_std.loc[:,['Packets','Elapsed Time (sec)','Bytes Received']])\n",
    "x_test_std.loc[:,['Packets','Elapsed Time (sec)','Bytes Received']] = scaler.fit_transform(x_test_std.loc[:,['Packets','Elapsed Time (sec)','Bytes Received']])\n",
    "\n",
    "x_train_robust.loc[:,['Packets','Elapsed Time (sec)','Bytes Received']] = robust.fit_transform(x_train_robust.loc[:,['Packets','Elapsed Time (sec)','Bytes Received']])\n",
    "x_test_robust.loc[:,['Packets','Elapsed Time (sec)','Bytes Received']] = robust.fit_transform(x_test_robust.loc[:,['Packets','Elapsed Time (sec)','Bytes Received']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91     11292\n",
      "           1       0.05      0.05      0.05      4496\n",
      "           2       0.00      0.00      0.00      3856\n",
      "           3       0.00      1.00      0.01        16\n",
      "\n",
      "    accuracy                           0.49     19660\n",
      "   macro avg       0.26      0.47      0.24     19660\n",
      "weighted avg       0.59      0.49      0.53     19660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier()\n",
    "clf.fit(x_train_robust,y_train_robust)\n",
    "answer = clf.predict(x_test_robust)\n",
    "print(classification_report(y_test_robust, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    {'activation':['identity','logistic','tanh','relu'],'learning_rate':['constant','invscaling','adaptive']} # ,'solver':['lbfgs','sgd','adam']\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Grid for Robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.72935\n",
      "Grid: {'activation': 'tanh', 'learning_rate': 'constant'}\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_grid = ''\n",
    "for g in ParameterGrid(parameters):\n",
    "    clf.set_params(**g)\n",
    "    clf.fit(x_train_robust,y_train_robust)\n",
    "    answer = clf.predict(x_test_robust)\n",
    "    f1 = f1_score(y_test_robust,answer,average='macro')\n",
    "\n",
    "    if f1 > best_score:\n",
    "        best_score = f1\n",
    "        best_grid = g\n",
    "print(\"F1: %0.5f\" % best_score)\n",
    "print(\"Grid:\", best_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97     25830\n",
      "           1       0.81      0.15      0.25     25165\n",
      "           2       1.00      1.00      1.00     26245\n",
      "           3       0.52      0.95      0.67     25744\n",
      "\n",
      "    accuracy                           0.77    102984\n",
      "   macro avg       0.83      0.76      0.72    102984\n",
      "weighted avg       0.83      0.77      0.73    102984\n",
      "\n",
      "Test Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94     11292\n",
      "           1       0.86      0.16      0.27      4496\n",
      "           2       0.99      1.00      1.00      3856\n",
      "           3       0.00      1.00      0.01        16\n",
      "\n",
      "    accuracy                           0.75     19660\n",
      "   macro avg       0.71      0.76      0.56     19660\n",
      "weighted avg       0.97      0.75      0.80     19660\n",
      "\n",
      "AVG F1-Score Train: 0.7230310256202703\n",
      "AVG F1-Score Test: 0.5553946416200737\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(activation='tanh',learning_rate='constant')\n",
    "clf.fit(x_train_robust,y_train_robust)\n",
    "\n",
    "train_yhat = clf.predict(x_train_robust)\n",
    "train_f1 = f1_score(y_train_robust,train_yhat,average='macro')\n",
    "\n",
    "test_yhat = clf.predict(x_test_robust)\n",
    "test_f1 = f1_score(y_test_robust,test_yhat,average='macro')\n",
    "print('Train Score\\n',classification_report(y_train_robust,train_yhat))\n",
    "print('Test Score\\n',classification_report(y_test_robust, test_yhat))\n",
    "print(f\"AVG F1-Score Train: {train_f1}\\nAVG F1-Score Test: {test_f1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Grid for std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.74016\n",
      "Grid: {'activation': 'tanh', 'learning_rate': 'invscaling'}\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_grid = ''\n",
    "for g in ParameterGrid(parameters):\n",
    "    clf.set_params(**g)\n",
    "    clf.fit(x_train_std,y_train_std)\n",
    "    answer = clf.predict(x_test_std)\n",
    "    f1 = f1_score(y_test_std,answer,average='macro')\n",
    "\n",
    "    if f1 > best_score:\n",
    "        best_score = f1\n",
    "        best_grid = g\n",
    "print(\"F1: %0.5f\" % best_score)\n",
    "print(\"Grid:\", best_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89     25830\n",
      "           1       0.56      1.00      0.72     25165\n",
      "           2       1.00      1.00      1.00     26245\n",
      "           3       0.37      0.00      0.00     25744\n",
      "\n",
      "    accuracy                           0.75    102984\n",
      "   macro avg       0.68      0.75      0.65    102984\n",
      "weighted avg       0.68      0.75      0.65    102984\n",
      "\n",
      "Test Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     11292\n",
      "           1       0.96      0.99      0.98      4496\n",
      "           2       0.99      1.00      0.99      3856\n",
      "           3       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.99     19660\n",
      "   macro avg       0.74      0.74      0.74     19660\n",
      "weighted avg       0.99      0.99      0.99     19660\n",
      "\n",
      "AVG F1-Score Train: 0.6518364775980865\n",
      "AVG F1-Score Test: 0.7399979487995794\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(activation='tanh',learning_rate='invscaling')\n",
    "clf.fit(x_train_std,y_train_std)\n",
    "\n",
    "train_yhat = clf.predict(x_train_std)\n",
    "train_f1 = f1_score(y_train_std,train_yhat,average='macro')\n",
    "\n",
    "test_yhat = clf.predict(x_test_std)\n",
    "test_f1 = f1_score(y_test_std,test_yhat,average='macro')\n",
    "print('Train Score\\n',classification_report(y_train_std,train_yhat))\n",
    "print('Test Score\\n',classification_report(y_test_std, test_yhat))\n",
    "print(f\"AVG F1-Score Train: {train_f1}\\nAVG F1-Score Test: {test_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7742\n"
     ]
    }
   ],
   "source": [
    "cross_std = cross_val_score(MLPClassifier(activation='tanh',learning_rate='constant'),x_train_robust,y_train_robust,cv=5)\n",
    "print(round(np.mean(cross_std),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7849\n"
     ]
    }
   ],
   "source": [
    "cross_std = cross_val_score(MLPClassifier(activation='tanh',learning_rate='invscaling'),x_train_robust,y_train_robust,cv=5)\n",
    "print(round(np.mean(cross_std),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
