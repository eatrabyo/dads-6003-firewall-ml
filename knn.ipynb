{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report,f1_score\n",
    "from sklearn.model_selection import GridSearchCV,ParameterGrid,cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('data_source/X_train.csv')\n",
    "y_train = pd.read_csv('data_source/y_train.csv')\n",
    "\n",
    "x_test = pd.read_csv('data_source/X_test.csv')\n",
    "y_test = pd.read_csv('data_source/y_test.csv')\n",
    "\n",
    "x_train_std = x_train.copy()\n",
    "y_train_std = y_train.copy()\n",
    "\n",
    "x_train_robust = x_train.copy()\n",
    "y_train_robust = y_train.copy()\n",
    "\n",
    "x_test_std = x_test.copy()\n",
    "y_test_std = y_test.copy()\n",
    "\n",
    "x_test_robust = x_test.copy()\n",
    "y_test_robust = y_test.copy()\n",
    "\n",
    "x_train_std = x_train_std.loc[:,['Destination Port', 'NAT Source Port','Packets', 'Elapsed Time (sec)','Bytes Received']]\n",
    "y_train_std = y_train_std.loc[:,'Action']\n",
    "x_test_std = x_test_std.loc[:,['Destination Port', 'NAT Source Port','Packets', 'Elapsed Time (sec)','Bytes Received']]\n",
    "y_test_std = y_test_std.loc[:,'Action']\n",
    "\n",
    "x_train_robust = x_train_robust.loc[:,['Destination Port', 'NAT Source Port','Packets', 'Elapsed Time (sec)','Bytes Received']]\n",
    "y_train_robust = y_train_robust.loc[:,'Action']\n",
    "x_test_robust = x_test_robust.loc[:,['Destination Port', 'NAT Source Port','Packets', 'Elapsed Time (sec)','Bytes Received']]\n",
    "y_test_robust = y_test_robust.loc[:,'Action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "robust = RobustScaler()\n",
    "x_train_std.loc[:,['Packets','Elapsed Time (sec)','Bytes Received']] = scaler.fit_transform(x_train_std.loc[:,['Packets','Elapsed Time (sec)','Bytes Received']])\n",
    "x_test_std.loc[:,['Packets','Elapsed Time (sec)','Bytes Received']] = scaler.fit_transform(x_test_std.loc[:,['Packets','Elapsed Time (sec)','Bytes Received']])\n",
    "\n",
    "x_train_robust.loc[:,['Packets','Elapsed Time (sec)','Bytes Received']] = robust.fit_transform(x_train_robust.loc[:,['Packets','Elapsed Time (sec)','Bytes Received']])\n",
    "x_test_robust.loc[:,['Packets','Elapsed Time (sec)','Bytes Received']] = robust.fit_transform(x_test_robust.loc[:,['Packets','Elapsed Time (sec)','Bytes Received']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     11292\n",
      "           1       0.97      0.98      0.97      4496\n",
      "           2       1.00      1.00      1.00      3856\n",
      "           3       0.04      0.62      0.07        16\n",
      "\n",
      "    accuracy                           0.98     19660\n",
      "   macro avg       0.75      0.89      0.76     19660\n",
      "weighted avg       0.99      0.98      0.98     19660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(x_train_std,y_train_std)\n",
    "answer = knn.predict(x_test_std)\n",
    "print(classification_report(y_test_std, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_neighbors':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'weights':['uniform', 'distance'],\n",
    "    'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute']}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter from Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto', 'n_neighbors': 9, 'weights': 'distance'}\n",
      "KNeighborsClassifier(n_neighbors=9, weights='distance')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     11292\n",
      "           1       0.96      0.96      0.96      4496\n",
      "           2       1.00      1.00      1.00      3856\n",
      "           3       0.03      0.94      0.06        16\n",
      "\n",
      "    accuracy                           0.97     19660\n",
      "   macro avg       0.75      0.96      0.75     19660\n",
      "weighted avg       0.99      0.97      0.98     19660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_best = GridSearchCV(knn, parameters, cv=5)\n",
    "#knn_best.fit(X,y_train)\n",
    "knn_best.fit(x_train_robust,y_train_robust)\n",
    "print(knn_best.best_params_)\n",
    "print(knn_best.best_estimator_)\n",
    "answer = knn_best.predict(x_test_robust)\n",
    "print(classification_report(y_test_robust, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     25830\n",
      "           1       0.89      0.94      0.91     25165\n",
      "           2       1.00      1.00      1.00     26245\n",
      "           3       0.94      0.89      0.91     25744\n",
      "\n",
      "    accuracy                           0.96    102984\n",
      "   macro avg       0.96      0.96      0.96    102984\n",
      "weighted avg       0.96      0.96      0.96    102984\n",
      "\n",
      "Test Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     11292\n",
      "           1       0.96      0.96      0.96      4496\n",
      "           2       1.00      1.00      1.00      3856\n",
      "           3       0.03      0.94      0.06        16\n",
      "\n",
      "    accuracy                           0.97     19660\n",
      "   macro avg       0.75      0.96      0.75     19660\n",
      "weighted avg       0.99      0.97      0.98     19660\n",
      "\n",
      "AVG F1-Score Train: 0.9566764274719737\n",
      "AVG F1-Score Test: 0.7505109293385833\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9,algorithm='auto',weights='distance')\n",
    "knn.fit(x_train_robust,y_train_robust)\n",
    "\n",
    "train_yhat = knn.predict(x_train_robust)\n",
    "train_f1 = f1_score(y_train_robust,train_yhat,average='macro')\n",
    "\n",
    "test_yhat = knn.predict(x_test_robust)\n",
    "test_f1 = f1_score(y_test_robust,test_yhat,average='macro')\n",
    "print('Train Score\\n',classification_report(y_train_robust,train_yhat))\n",
    "print('Test Score\\n',classification_report(y_test_robust, test_yhat))\n",
    "print(f\"AVG F1-Score Train: {train_f1}\\nAVG F1-Score Test: {test_f1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter grid for Standardize transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.75928\n",
      "Grid: {'algorithm': 'ball_tree', 'n_neighbors': 4, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_grid = ''\n",
    "for g in ParameterGrid(parameters):\n",
    "    knn.set_params(**g)\n",
    "    knn.fit(x_train_std,y_train_std)\n",
    "    answer = knn.predict(x_test_std)\n",
    "    f1 = f1_score(y_test_std,answer,average='macro')\n",
    "\n",
    "    if f1 > best_score:\n",
    "        best_score = f1\n",
    "        best_grid = g\n",
    "print(\"F1: %0.5f\" % best_score)\n",
    "print(\"Grid:\", best_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     25830\n",
      "           1       0.77      0.98      0.86     25165\n",
      "           2       1.00      1.00      1.00     26245\n",
      "           3       0.96      0.71      0.82     25744\n",
      "\n",
      "    accuracy                           0.92    102984\n",
      "   macro avg       0.93      0.92      0.92    102984\n",
      "weighted avg       0.93      0.92      0.92    102984\n",
      "\n",
      "Test Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     11292\n",
      "           1       0.97      0.98      0.97      4496\n",
      "           2       1.00      1.00      1.00      3856\n",
      "           3       0.04      0.62      0.08        16\n",
      "\n",
      "    accuracy                           0.98     19660\n",
      "   macro avg       0.75      0.89      0.76     19660\n",
      "weighted avg       0.99      0.98      0.99     19660\n",
      "\n",
      "AVG F1-Score Train: 0.9195590918206044\n",
      "AVG F1-Score Test: 0.7592758028332826\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=4,algorithm='ball_tree',weights='uniform')\n",
    "knn.fit(x_train_std,y_train_std)\n",
    "\n",
    "train_yhat = knn.predict(x_train_std)\n",
    "train_f1 = f1_score(y_train_std,train_yhat,average='macro')\n",
    "\n",
    "test_yhat = knn.predict(x_test_std)\n",
    "test_f1 = f1_score(y_test_std,test_yhat,average='macro')\n",
    "print('Train Score\\n',classification_report(y_train_std,train_yhat))\n",
    "print('Test Score\\n',classification_report(y_test_std, test_yhat))\n",
    "print(f\"AVG F1-Score Train: {train_f1}\\nAVG F1-Score Test: {test_f1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter for Robust transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.75365\n",
      "Grid: {'algorithm': 'brute', 'n_neighbors': 4, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_grid = ''\n",
    "for g in ParameterGrid(parameters):\n",
    "    knn.set_params(**g)\n",
    "    knn.fit(x_train_robust,y_train_robust)\n",
    "    answer = knn.predict(x_test_robust)\n",
    "    f1 = f1_score(y_test_robust,answer,average='macro')\n",
    "\n",
    "    if f1 > best_score:\n",
    "        best_score = f1\n",
    "        best_grid = g\n",
    "print(\"F1: %0.5f\" % best_score)\n",
    "print(\"Grid:\", best_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     25830\n",
      "           1       0.77      0.98      0.86     25165\n",
      "           2       1.00      1.00      1.00     26245\n",
      "           3       0.97      0.72      0.82     25744\n",
      "\n",
      "    accuracy                           0.92    102984\n",
      "   macro avg       0.93      0.92      0.92    102984\n",
      "weighted avg       0.93      0.92      0.92    102984\n",
      "\n",
      "Test Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     11292\n",
      "           1       0.97      0.98      0.97      4496\n",
      "           2       1.00      1.00      1.00      3856\n",
      "           3       0.03      0.62      0.06        16\n",
      "\n",
      "    accuracy                           0.98     19660\n",
      "   macro avg       0.75      0.89      0.75     19660\n",
      "weighted avg       0.99      0.98      0.98     19660\n",
      "\n",
      "AVG F1-Score Train: 0.9203482948476003\n",
      "AVG F1-Score Test: 0.7536457020645934\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=4,algorithm='brute',weights='uniform')\n",
    "knn.fit(x_train_robust,y_train_robust)\n",
    "\n",
    "train_yhat = knn.predict(x_train_robust)\n",
    "train_f1 = f1_score(y_train_robust,train_yhat,average='macro')\n",
    "\n",
    "test_yhat = knn.predict(x_test_robust)\n",
    "test_f1 = f1_score(y_test_robust,test_yhat,average='macro')\n",
    "print('Train Score\\n',classification_report(y_train_robust,train_yhat))\n",
    "print('Test Score\\n',classification_report(y_test_robust, test_yhat))\n",
    "print(f\"AVG F1-Score Train: {train_f1}\\nAVG F1-Score Test: {test_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9137\n"
     ]
    }
   ],
   "source": [
    "cross_std = cross_val_score(KNeighborsClassifier(n_neighbors=4,algorithm='ball_tree',weights='uniform'),x_train_std,y_train_std,cv=5)\n",
    "print(round(np.mean(cross_std),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9146\n"
     ]
    }
   ],
   "source": [
    "cross_std = cross_val_score(KNeighborsClassifier(n_neighbors=4,algorithm='brute',weights='uniform'),x_train_robust,y_train_robust,cv=5)\n",
    "print(round(np.mean(cross_std),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Source Port', 'Destination Port', 'NAT Source Port',\n",
       "       'NAT Destination Port', 'Bytes', 'Bytes Sent', 'Bytes Received',\n",
       "       'Packets', 'Elapsed Time (sec)', 'pkts_sent', 'pkts_received'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gridsearch for FCLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_f_std = x_train.copy()\n",
    "y_train_f_std = y_train.copy()\n",
    "\n",
    "x_test_f_std = x_test.copy()\n",
    "y_test_f_std = y_test.copy()\n",
    "\n",
    "x_train_f_std = x_train_f_std.loc[:,['pkts_received','Packets', 'Elapsed Time (sec)','Bytes Received']]\n",
    "y_train_f_std = y_train_f_std.loc[:,'Action']\n",
    "x_test_f_std = x_test_f_std.loc[:,['pkts_received','Packets', 'Elapsed Time (sec)','Bytes Received']]\n",
    "y_test_f_std = y_test_f_std.loc[:,'Action']\n",
    "\n",
    "\n",
    "x_train_f_robust = x_train.copy()\n",
    "y_train_f_robust = y_train.copy()\n",
    "\n",
    "x_test_f_robust = x_test.copy()\n",
    "y_test_f_robust = y_test.copy()\n",
    "\n",
    "x_train_f_robust = x_train_f_robust.loc[:,['pkts_received','Packets', 'Elapsed Time (sec)','Bytes Received']]\n",
    "y_train_f_robust = y_train_f_robust.loc[:,'Action']\n",
    "x_test_f_robust = x_test_f_robust.loc[:,['pkts_received','Packets', 'Elapsed Time (sec)','Bytes Received']]\n",
    "y_test_f_robust = y_test_f_robust.loc[:,'Action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "robust = RobustScaler()\n",
    "x_train_f_std = scaler.fit_transform(x_train_f_std)\n",
    "x_test_f_std = scaler.fit_transform(x_test_f_std)\n",
    "\n",
    "x_train_f_robust = robust.fit_transform(x_train_f_robust)\n",
    "x_test_f_robust = robust.fit_transform(x_test_f_robust)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.78      0.88     11292\n",
      "           1       0.42      1.00      0.59      4496\n",
      "           2       0.00      0.00      0.00      3856\n",
      "           3       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.68     19660\n",
      "   macro avg       0.36      0.45      0.37     19660\n",
      "weighted avg       0.67      0.68      0.64     19660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_best = GridSearchCV(knn, parameters, cv=5)\n",
    "#knn_best.fit(X,y_train)\n",
    "knn_best.fit(x_train_f_std,y_train_f_std)\n",
    "print(knn_best.best_params_)\n",
    "print(knn_best.best_estimator_)\n",
    "answer = knn_best.predict(x_test_f_std)\n",
    "print(classification_report(y_test_f_std, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     25830\n",
      "           1       0.35      1.00      0.52     25165\n",
      "           2       0.00      0.00      0.00     26245\n",
      "           3       1.00      0.24      0.38     25744\n",
      "\n",
      "    accuracy                           0.55    102984\n",
      "   macro avg       0.59      0.56      0.48    102984\n",
      "weighted avg       0.59      0.55      0.47    102984\n",
      "\n",
      "Test Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.78      0.88     11292\n",
      "           1       0.42      1.00      0.59      4496\n",
      "           2       0.00      0.00      0.00      3856\n",
      "           3       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.68     19660\n",
      "   macro avg       0.36      0.45      0.37     19660\n",
      "weighted avg       0.67      0.68      0.64     19660\n",
      "\n",
      "AVG F1-Score Train: 0.47695517855756975\n",
      "AVG F1-Score Test: 0.3678591135050651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3,algorithm='auto',weights='distance')\n",
    "knn.fit(x_train_f_std,y_train_f_std)\n",
    "\n",
    "train_yhat = knn.predict(x_train_f_std)\n",
    "train_f1 = f1_score(y_train_f_std,train_yhat,average='macro')\n",
    "\n",
    "test_yhat = knn.predict(x_test_f_std)\n",
    "test_f1 = f1_score(y_test_f_std,test_yhat,average='macro')\n",
    "print('Train Score\\n',classification_report(y_train_f_std,train_yhat))\n",
    "print('Test Score\\n',classification_report(y_test_f_std, test_yhat))\n",
    "print(f\"AVG F1-Score Train: {train_f1}\\nAVG F1-Score Test: {test_f1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "KNeighborsClassifier(n_neighbors=1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.48      0.65     11292\n",
      "           1       0.49      1.00      0.66      4496\n",
      "           2       0.00      0.00      0.00      3856\n",
      "           3       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.50     19660\n",
      "   macro avg       0.37      0.37      0.33     19660\n",
      "weighted avg       0.69      0.50      0.52     19660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_best = GridSearchCV(knn, parameters, cv=5)\n",
    "#knn_best.fit(X,y_train)\n",
    "knn_best.fit(x_train_f_robust,y_train_f_robust)\n",
    "print(knn_best.best_params_)\n",
    "print(knn_best.best_estimator_)\n",
    "answer = knn_best.predict(x_test_f_robust)\n",
    "print(classification_report(y_test_f_robust, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     25830\n",
      "           1       0.35      1.00      0.52     25165\n",
      "           2       0.00      0.00      0.00     26245\n",
      "           3       1.00      0.24      0.38     25744\n",
      "\n",
      "    accuracy                           0.55    102984\n",
      "   macro avg       0.59      0.56      0.48    102984\n",
      "weighted avg       0.59      0.55      0.47    102984\n",
      "\n",
      "Test Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.48      0.65     11292\n",
      "           1       0.49      1.00      0.66      4496\n",
      "           2       0.00      0.00      0.00      3856\n",
      "           3       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.50     19660\n",
      "   macro avg       0.37      0.37      0.33     19660\n",
      "weighted avg       0.69      0.50      0.52     19660\n",
      "\n",
      "AVG F1-Score Train: 0.47695517855756975\n",
      "AVG F1-Score Test: 0.32651879865532585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1,algorithm='auto',weights='uniform')\n",
    "knn.fit(x_train_f_robust,y_train_f_robust)\n",
    "\n",
    "train_yhat = knn.predict(x_train_f_robust)\n",
    "train_f1 = f1_score(y_train_f_robust,train_yhat,average='macro')\n",
    "\n",
    "test_yhat = knn.predict(x_test_f_robust)\n",
    "test_f1 = f1_score(y_test_f_robust,test_yhat,average='macro')\n",
    "print('Train Score\\n',classification_report(y_train_f_robust,train_yhat))\n",
    "print('Test Score\\n',classification_report(y_test_f_robust, test_yhat))\n",
    "print(f\"AVG F1-Score Train: {train_f1}\\nAVG F1-Score Test: {test_f1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gridsearch RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rf_std = x_train.copy()\n",
    "y_train_rf_std = y_train.copy()\n",
    "\n",
    "x_test_rf_std = x_test.copy()\n",
    "y_test_rf_std = y_test.copy()\n",
    "\n",
    "x_train_rf_std = x_train_rf_std.loc[:,['Source Port', 'NAT Source Port',\n",
    "       'NAT Destination Port', 'Bytes', 'Bytes Sent', 'Bytes Received',\n",
    "       'Packets', 'Elapsed Time (sec)', 'pkts_sent', 'pkts_received']]\n",
    "y_train_rf_std = y_train_rf_std.loc[:,'Action']\n",
    "x_test_rf_std = x_test_rf_std.loc[:,['Source Port', 'NAT Source Port',\n",
    "       'NAT Destination Port', 'Bytes', 'Bytes Sent', 'Bytes Received',\n",
    "       'Packets', 'Elapsed Time (sec)', 'pkts_sent', 'pkts_received']]\n",
    "y_test_rf_std = y_test_rf_std.loc[:,'Action']\n",
    "\n",
    "\n",
    "x_train_rf_robust = x_train.copy()\n",
    "y_train_rf_robust = y_train.copy()\n",
    "\n",
    "x_test_rf_robust = x_test.copy()\n",
    "y_test_rf_robust = y_test.copy()\n",
    "\n",
    "x_train_rf_robust = x_train_rf_robust.loc[:,['Source Port', 'NAT Source Port',\n",
    "       'NAT Destination Port', 'Bytes', 'Bytes Sent', 'Bytes Received',\n",
    "       'Packets', 'Elapsed Time (sec)', 'pkts_sent', 'pkts_received']]\n",
    "y_train_rf_robust = y_train_rf_robust.loc[:,'Action']\n",
    "x_test_rf_robust = x_test_rf_robust.loc[:,['Source Port', 'NAT Source Port',\n",
    "       'NAT Destination Port', 'Bytes', 'Bytes Sent', 'Bytes Received',\n",
    "       'Packets', 'Elapsed Time (sec)', 'pkts_sent', 'pkts_received']]\n",
    "y_test_rf_robust = y_test_rf_robust.loc[:,'Action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "robust = RobustScaler()\n",
    "x_train_rf_std = scaler.fit_transform(x_train_rf_std.loc[:,['Bytes','Bytes Sent', 'Bytes Received','Packets', 'Elapsed Time (sec)', 'pkts_sent', 'pkts_received']])\n",
    "x_test_rf_std = scaler.fit_transform(x_test_rf_std.loc[:,['Bytes','Bytes Sent', 'Bytes Received','Packets', 'Elapsed Time (sec)', 'pkts_sent', 'pkts_received']])\n",
    "\n",
    "x_train_rf_robust = robust.fit_transform(x_train_rf_robust.loc[:,['Bytes','Bytes Sent', 'Bytes Received','Packets', 'Elapsed Time (sec)', 'pkts_sent', 'pkts_received']])\n",
    "x_test_rf_robust = robust.fit_transform(x_test_rf_robust.loc[:,['Bytes','Bytes Sent', 'Bytes Received','Packets', 'Elapsed Time (sec)', 'pkts_sent', 'pkts_received']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto', 'n_neighbors': 9, 'weights': 'distance'}\n",
      "KNeighborsClassifier(n_neighbors=9, weights='distance')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.78      0.88     11292\n",
      "           1       0.41      1.00      0.59      4496\n",
      "           2       0.00      0.00      0.00      3856\n",
      "           3       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.68     19660\n",
      "   macro avg       0.35      0.45      0.37     19660\n",
      "weighted avg       0.67      0.68      0.64     19660\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "knn_best = GridSearchCV(knn, parameters, cv=5)\n",
    "#knn_best.fit(X,y_train)\n",
    "knn_best.fit(x_train_rf_std,y_train_rf_std)\n",
    "print(knn_best.best_params_)\n",
    "print(knn_best.best_estimator_)\n",
    "answer = knn_best.predict(x_test_rf_std)\n",
    "print(classification_report(y_test_rf_std, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     25830\n",
      "           1       0.35      1.00      0.52     25165\n",
      "           2       0.00      0.00      0.00     26245\n",
      "           3       1.00      0.24      0.38     25744\n",
      "\n",
      "    accuracy                           0.55    102984\n",
      "   macro avg       0.59      0.56      0.48    102984\n",
      "weighted avg       0.59      0.55      0.47    102984\n",
      "\n",
      "Test Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.78      0.88     11292\n",
      "           1       0.41      1.00      0.59      4496\n",
      "           2       0.00      0.00      0.00      3856\n",
      "           3       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.68     19660\n",
      "   macro avg       0.35      0.45      0.37     19660\n",
      "weighted avg       0.67      0.68      0.64     19660\n",
      "\n",
      "AVG F1-Score Train: 0.4770480209357309\n",
      "AVG F1-Score Test: 0.365879562791236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9,algorithm='auto',weights='distance')\n",
    "knn.fit(x_train_rf_std,y_train_rf_std)\n",
    "\n",
    "train_yhat = knn.predict(x_train_rf_std)\n",
    "train_f1 = f1_score(y_train_rf_std,train_yhat,average='macro')\n",
    "\n",
    "test_yhat = knn.predict(x_test_rf_std)\n",
    "test_f1 = f1_score(y_test_rf_std,test_yhat,average='macro')\n",
    "print('Train Score\\n',classification_report(y_train_rf_std,train_yhat))\n",
    "print('Test Score\\n',classification_report(y_test_rf_std, test_yhat))\n",
    "print(f\"AVG F1-Score Train: {train_f1}\\nAVG F1-Score Test: {test_f1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto', 'n_neighbors': 9, 'weights': 'distance'}\n",
      "KNeighborsClassifier(n_neighbors=9, weights='distance')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.39      0.56     11292\n",
      "           1       0.45      1.00      0.62      4496\n",
      "           2       0.00      0.00      0.00      3856\n",
      "           3       0.00      0.19      0.00        16\n",
      "\n",
      "    accuracy                           0.45     19660\n",
      "   macro avg       0.36      0.39      0.30     19660\n",
      "weighted avg       0.68      0.45      0.46     19660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_best = GridSearchCV(knn, parameters, cv=5)\n",
    "#knn_best.fit(X,y_train)\n",
    "knn_best.fit(x_train_rf_robust,y_train_rf_robust)\n",
    "print(knn_best.best_params_)\n",
    "print(knn_best.best_estimator_)\n",
    "answer = knn_best.predict(x_test_rf_robust)\n",
    "print(classification_report(y_test_rf_robust, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     25830\n",
      "           1       0.36      1.00      0.53     25165\n",
      "           2       0.00      0.00      0.00     26245\n",
      "           3       0.99      0.26      0.41     25744\n",
      "\n",
      "    accuracy                           0.56    102984\n",
      "   macro avg       0.59      0.56      0.48    102984\n",
      "weighted avg       0.59      0.56      0.48    102984\n",
      "\n",
      "Test Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.39      0.56     11292\n",
      "           1       0.45      1.00      0.62      4496\n",
      "           2       0.00      0.00      0.00      3856\n",
      "           3       0.00      0.19      0.00        16\n",
      "\n",
      "    accuracy                           0.45     19660\n",
      "   macro avg       0.36      0.39      0.30     19660\n",
      "weighted avg       0.68      0.45      0.46     19660\n",
      "\n",
      "AVG F1-Score Train: 0.48405744819879537\n",
      "AVG F1-Score Test: 0.29547386060299125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9,algorithm='auto',weights='distance')\n",
    "knn.fit(x_train_rf_robust,y_train_rf_robust)\n",
    "\n",
    "train_yhat = knn.predict(x_train_rf_robust)\n",
    "train_f1 = f1_score(y_train_rf_robust,train_yhat,average='macro')\n",
    "\n",
    "test_yhat = knn.predict(x_test_rf_robust)\n",
    "test_f1 = f1_score(y_test_rf_robust,test_yhat,average='macro')\n",
    "print('Train Score\\n',classification_report(y_train_rf_robust,train_yhat))\n",
    "print('Test Score\\n',classification_report(y_test_rf_robust, test_yhat))\n",
    "print(f\"AVG F1-Score Train: {train_f1}\\nAVG F1-Score Test: {test_f1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch NAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_nad_std = x_train.copy()\n",
    "y_train_nad_std = y_train.copy()\n",
    "\n",
    "x_test_nad_std = x_test.copy()\n",
    "y_test_nad_std = y_test.copy()\n",
    "\n",
    "x_train_nad_std = x_train_nad_std.loc[:,[ 'Bytes Sent', 'Bytes Received', 'pkts_sent', 'pkts_received']]\n",
    "y_train_nad_std = y_train_nad_std.loc[:,'Action']\n",
    "x_test_nad_std = x_test_nad_std.loc[:,[ 'Bytes Sent', 'Bytes Received', 'pkts_sent', 'pkts_received']]\n",
    "y_test_nad_std = y_test_nad_std.loc[:,'Action']\n",
    "\n",
    "\n",
    "x_train_nad_robust = x_train.copy()\n",
    "y_train_nad_robust = y_train.copy()\n",
    "\n",
    "x_test_nad_robust = x_test.copy()\n",
    "y_test_nad_robust = y_test.copy()\n",
    "\n",
    "x_train_nad_robust = x_train_nad_robust.loc[:,[ 'Bytes Sent', 'Bytes Received', 'pkts_sent', 'pkts_received']]\n",
    "y_train_nad_robust = y_train_nad_robust.loc[:,'Action']\n",
    "x_test_nad_robust = x_test_nad_robust.loc[:,[ 'Bytes Sent', 'Bytes Received', 'pkts_sent', 'pkts_received']]\n",
    "y_test_nad_robust = y_test_nad_robust.loc[:,'Action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "robust = RobustScaler()\n",
    "x_train_nad_std = scaler.fit_transform(x_train_nad_std.loc[ :,['Bytes Sent', 'Bytes Received', 'pkts_sent', 'pkts_received']])\n",
    "x_test_nad_std = scaler.fit_transform(x_test_nad_std.loc[ :,['Bytes Sent', 'Bytes Received', 'pkts_sent', 'pkts_received']])\n",
    "\n",
    "x_train_nad_robust = robust.fit_transform(x_train_nad_robust.loc[ :,['Bytes Sent', 'Bytes Received', 'pkts_sent', 'pkts_received']])\n",
    "x_test_nad_robust = robust.fit_transform(x_test_nad_robust.loc[ :,['Bytes Sent', 'Bytes Received', 'pkts_sent', 'pkts_received']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "KNeighborsClassifier(weights='distance')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.97      0.72     11292\n",
      "           1       0.00      0.00      0.00      4496\n",
      "           2       0.00      0.00      0.00      3856\n",
      "           3       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.56     19660\n",
      "   macro avg       0.14      0.24      0.18     19660\n",
      "weighted avg       0.33      0.56      0.41     19660\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "knn_best = GridSearchCV(knn, parameters, cv=5)\n",
    "#knn_best.fit(X,y_train)\n",
    "knn_best.fit(x_train_nad_std,y_train_nad_std)\n",
    "print(knn_best.best_params_)\n",
    "print(knn_best.best_estimator_)\n",
    "answer = knn_best.predict(x_test_nad_std)\n",
    "print(classification_report(y_test_nad_std, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      1.00      0.53     25830\n",
      "           1       0.28      0.28      0.28     25165\n",
      "           2       0.00      0.00      0.00     26245\n",
      "           3       1.00      0.25      0.40     25744\n",
      "\n",
      "    accuracy                           0.38    102984\n",
      "   macro avg       0.41      0.38      0.30    102984\n",
      "weighted avg       0.41      0.38      0.30    102984\n",
      "\n",
      "Test Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.97      0.72     11292\n",
      "           1       0.00      0.00      0.00      4496\n",
      "           2       0.00      0.00      0.00      3856\n",
      "           3       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.56     19660\n",
      "   macro avg       0.14      0.24      0.18     19660\n",
      "weighted avg       0.33      0.56      0.41     19660\n",
      "\n",
      "AVG F1-Score Train: 0.30335877265770783\n",
      "AVG F1-Score Test: 0.17886311662855275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5,algorithm='auto',weights='distance')\n",
    "knn.fit(x_train_nad_std,y_train_nad_std)\n",
    "\n",
    "train_yhat = knn.predict(x_train_nad_std)\n",
    "train_f1 = f1_score(y_train_nad_std,train_yhat,average='macro')\n",
    "\n",
    "test_yhat = knn.predict(x_test_nad_std)\n",
    "test_f1 = f1_score(y_test_nad_std,test_yhat,average='macro')\n",
    "print('Train Score\\n',classification_report(y_train_nad_std,train_yhat))\n",
    "print('Test Score\\n',classification_report(y_test_nad_std, test_yhat))\n",
    "print(f\"AVG F1-Score Train: {train_f1}\\nAVG F1-Score Test: {test_f1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "KNeighborsClassifier(n_neighbors=1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.61      0.53     11292\n",
      "           1       0.68      0.14      0.24      4496\n",
      "           2       0.00      0.00      0.00      3856\n",
      "           3       0.00      0.19      0.00        16\n",
      "\n",
      "    accuracy                           0.38     19660\n",
      "   macro avg       0.29      0.23      0.19     19660\n",
      "weighted avg       0.43      0.38      0.36     19660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_best = GridSearchCV(knn, parameters, cv=5)\n",
    "#knn_best.fit(X,y_train)\n",
    "knn_best.fit(x_train_nad_robust,y_train_nad_robust)\n",
    "print(knn_best.best_params_)\n",
    "print(knn_best.best_estimator_)\n",
    "answer = knn_best.predict(x_test_nad_robust)\n",
    "print(classification_report(y_test_nad_robust, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      1.00      0.52     25830\n",
      "           1       0.26      0.24      0.25     25165\n",
      "           2       0.00      0.00      0.00     26245\n",
      "           3       0.99      0.27      0.42     25744\n",
      "\n",
      "    accuracy                           0.38    102984\n",
      "   macro avg       0.40      0.38      0.30    102984\n",
      "weighted avg       0.40      0.38      0.30    102984\n",
      "\n",
      "Test Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.61      0.53     11292\n",
      "           1       0.68      0.14      0.24      4496\n",
      "           2       0.00      0.00      0.00      3856\n",
      "           3       0.00      0.19      0.00        16\n",
      "\n",
      "    accuracy                           0.38     19660\n",
      "   macro avg       0.29      0.23      0.19     19660\n",
      "weighted avg       0.43      0.38      0.36     19660\n",
      "\n",
      "AVG F1-Score Train: 0.29822524343756746\n",
      "AVG F1-Score Test: 0.1926388296012017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/itthisak/Desktop/Nida/dads-6003-firewall-ml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1,algorithm='auto',weights='uniform')\n",
    "knn.fit(x_train_nad_robust,y_train_nad_robust)\n",
    "\n",
    "train_yhat = knn.predict(x_train_nad_robust)\n",
    "train_f1 = f1_score(y_train_nad_robust,train_yhat,average='macro')\n",
    "\n",
    "test_yhat = knn.predict(x_test_nad_robust)\n",
    "test_f1 = f1_score(y_test_nad_robust,test_yhat,average='macro')\n",
    "print('Train Score\\n',classification_report(y_train_nad_robust,train_yhat))\n",
    "print('Test Score\\n',classification_report(y_test_nad_robust, test_yhat))\n",
    "print(f\"AVG F1-Score Train: {train_f1}\\nAVG F1-Score Test: {test_f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
